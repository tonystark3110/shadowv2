Addressing challenges related to shadow removal in scene understanding, this paper introduces two innovative approaches. Firstly, a novel network structure named the Dual Hierarchically Aggregation Network (DHAN) is proposed. DHAN incorporates growth dilated convolutions as the backbone, without down-samplings, and employs hierarchical aggregation of multi-context features for attention and prediction. This design aims to learn images free from border artifacts in shadow regions. Secondly, recognizing that training on limited datasets hampers textural understanding, particularly causing color inconsistencies in shadow regions, a Shadow Matting Generative Adversarial Network (SMGAN) is introduced. SMGAN synthesizes realistic shadow mattings from a given shadow mask and shadow-free image. Due to the limited diversity in existing datasets, an augmentation strategy is employed using SMGAN to enhance datasets with novel masks and scenes. Experimental results demonstrate the effectiveness of DHAN in erasing shadows and generating high-quality, ghost-free images. Notably, after training on both synthesized and real datasets, DHAN surpasses other state-of-the-art methods significantly.
